# -*- coding: utf-8 -*-
"""Alberta Workforce and Economic Trend Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AGKuwHKIhE59anzgkKsg7shGVzLN4U8K

## Guiding Questions
<font size="4">
1. How does gender-based employment vary across different industries?<br>
2. Which industries experienced the highest percentage growth in female employment between 2001 and 2024?<br>
3. Are certain industries dominated by specific age groups?<br>
4. What is the distribution of full-time vs. part-time employment across industries?<br>
5. How has the proportion of male and female employment changed over time?<br>
6. Which are the top 5 industries with the highest and lowest average weekly earnings?<br>
7. What is the overall distribution of average weekly earnings across different industries?<br>
8. What are the average weekly earnings and average employment for each industry?<br>
9. Which industries are biggest and least in terms of providing employment opportunities?<br>
10. Which industries in Alberta lost the most jobs during the COVID period (March 2020 to December 2021)?<br>
11. Did industries with higher GDP before COVID suffer less during the pandemic?<br>
12. Which industries have seen the highest growth in GDP, and how do they compare in employment levels/average earnings?
</font>

<h2>Importing Libraries</h2>
"""

import pandas as pd
from sqlalchemy import create_engine, text
import sqlalchemy as sq
import matplotlib.pyplot as plt
from sqlalchemy import inspect
import numpy as np
import plotly.express as px
from scipy import stats
import seaborn as sns

"""<h2> Individual Datasets </h2>"""

labourForce= pd.read_csv('Labour force characteristics by industry, annual.csv')
display(labourForce.head())

avgEarning = pd.read_csv('Average weekly earnings by industry, monthly, unadjusted for seasonality.csv')
display(avgEarning.head())

employmentData = pd.read_csv("Employment by industry, monthly, unadjusted for seasonality.csv")
display(employmentData.head())

gdp = pd.read_csv("Gross domestic product (GDP) at basic prices, by industry, provinces and territories.csv")
display(gdp.head())

"""# Data Exploration

**Connect to Database** <br>
"""

engine = sq.create_engine('mysql+mysqlconnector://project:sWMPnkbZdwDmL@localhost/project')
conn = engine.connect()

"""## Data Exploration - Part 1
**Labour force characteristics by industry: Cleaning and Data analysis**

**Cleaning - Dataset Labour Force - Part 1**
"""

#Cleaning column values of Industry Classification and Gender
labourForce['North American Industry Classification System (NAICS)'] = labourForce['North American Industry Classification System (NAICS)'] .str.replace(r'\s*\[.*?\]\s*', '', regex=True).str.replace('\n', ' ', regex=True).str.strip()
labourForce['Gender'] = labourForce['Gender'].str.replace(r'[^a-zA-Z0-9 ]', '', regex=True)

"""**Dataframe to SQL - Labour Force Data**"""

labourForce_sql=labourForce.to_sql('LabourForce_table',engine,if_exists='replace', chunksize=5000 ,index=False)
#chunksize will break our rows into batches, which will help in managing memory and improve performance.
print("DataFrame successfully converted to SQL table!")

"""**Check column names of LabourForce table**"""

i = inspect(engine)
for column in i.get_columns('LabourForce_table'):
    print(f"{column['name']},{column['type']}")

"""**Count of Labour force data, Unique values of columns like Type of Labour Force and Industry Classification**"""

labourForce_count=pd.read_sql("SELECT COUNT(*) FROM LabourForce_table;",engine)
display(labourForce_count)
labourForce_type=pd.read_sql('SELECT DISTINCT `Labour force characteristics` FROM LabourForce_table;', engine)
display(labourForce_type)
naics=pd.read_sql('SELECT DISTINCT `North American Industry Classification System (NAICS)` FROM LabourForce_table;', engine)
display(naics)

"""**Cleaning - Dataset Labour Force - Part 2**"""

cleaning_labourForce_Data = [

    "DROP TABLE IF EXISTS years;",
    "DROP TABLE IF EXISTS geo;",
    "DROP TABLE IF EXISTS cleaned_LabourForce;",
    "DROP TABLE IF EXISTS filtered_LabourForce;",
    "DROP TABLE IF EXISTS final_LabourForce;",


    """CREATE TABLE years AS
    SELECT * FROM LabourForce_table
    WHERE CAST(REF_DATE AS INTEGER) BETWEEN 2001 AND 2024;""",

    """CREATE TABLE geo AS
    SELECT * FROM years
    WHERE TRIM(GEO) = 'Alberta';""",

    """CREATE TABLE cleaned_LabourForce AS
    SELECT `REF_DATE` AS YEAR,`GEO` AS Province,Gender AS Gender,
    `Labour force characteristics` AS `Characteristics`,
    `North American Industry Classification System (NAICS)` AS `Industry`,
    `Age group` AS Age_Group,
    COALESCE(VALUE, 0) AS Value FROM geo;""",

    """CREATE TABLE filtered_LabourForce AS
    SELECT * FROM cleaned_LabourForce WHERE
    LOWER(TRIM(Industry)) != 'total, all industries'
    AND LOWER(TRIM(Gender)) NOT LIKE '%total%gender%'
    AND LOWER(TRIM(Age_Group)) != '15 years and over'
    AND LOWER(TRIM(Characteristics)) != 'Employment';""",

    """CREATE TABLE final_LabourForce AS
    SELECT YEAR, Province, Characteristics, Industry, Gender, Age_Group, Value
    FROM filtered_LabourForce WHERE Industry NOT IN (
    'Industrial aggregate excluding unclassified businesses',
    'Goods-producing sector',
    'Durables',
    'Non-durables',
    'Services-producing sector',
    'Unclassified industries',
    'Forestry, fishing, mining, quarrying, oil and gas',
    'Fishing, hunting and trapping',
    'Wholesale trade',
    'Retail trade',
    'Finance, insurance, real estate, rental and leasing');""" ]


for query in cleaning_labourForce_Data:
    conn.execute(text(query))
print("The Labour Force dataset has been successfully cleaned!")

final_Labourdata = pd.read_sql("SELECT* FROM final_LabourForce", engine)
final_Labourdata.head()

final_data_count = pd.read_sql("SELECT COUNT(*) FROM final_LabourForce", engine)
final_data_count

"""### Guiding Questions - Part 1

<font size="4">1. How does gender-based employment vary across different industries?</font>
"""

genderParticipation= """SELECT Industry,Gender,SUM(Value) AS Total_Employment_in_thousands
FROM final_LabourForce GROUP BY Industry, Gender ORDER BY Total_Employment_in_thousands DESC ;"""
genderParticipation=pd.read_sql(genderParticipation, engine)
display(genderParticipation.head())
display(genderParticipation.tail())
#visual
men=genderParticipation.loc[genderParticipation['Gender'] == 'Men', ['Industry','Total_Employment_in_thousands']].sort_values('Industry')
women=genderParticipation.loc[genderParticipation['Gender'] == 'Women', ['Industry','Total_Employment_in_thousands']].sort_values('Industry')

classification=women['Industry'].values
men_values = men['Total_Employment_in_thousands'].values
women_values = women['Total_Employment_in_thousands'].values

x= np.arange(len(classification))
bar_width=0.40

fig, ax = plt.subplots(figsize=(14, 6))
bar1=ax.bar(x - bar_width/2, men_values, width=bar_width, label='Men')
bar2=ax.bar(x + bar_width/2, women_values, width=bar_width, label='Women')
for bars in [bar1,bar2]:
    for bar in bars:
        height=bar.get_height()
        if height>0:
            ax.text(bar.get_x()+bar.get_width()/2,height,f'{height:,.0f}',ha="center",va="bottom",fontsize=9,color='black')


plt.xticks(x,classification,rotation=90, ha='right')
plt.xlabel('Industry Classification')
plt.legend()
plt.ylabel('Total Employment (thousands)')
plt.title('Gender Participation by Industry')

"""-----------------------------------------------------------------------------------
The way jobs are split between men and women varies a lot in different industries, with some fields having a much higher number of one gender than the other.

- Men dominate industries like *Construction* (9,822.8K), *Wholesale and retail trade* (8,509.2 K), *Mining, quarrying, and oil and gas extraction* (5,396.1K) while women lead in *Healthcare and social assistance* (9,553.8K) and *Wholesale and retail trade* (7,803 K).
- Although *wholesale and retail trade* utilize both sexes in comparatively higher numbers, the male-biased disparity persists (8,509.2 thousand men compared to 7,803 thousand women).
-----------------------------------------------------------------------------------

<font size="4">2. Which industries experienced the highest percentage growth in female employment between 2001 and 2024?</font>
"""

femaleCount=pd.read_sql("""SELECT Industry, YEAR, SUM(Value) AS Female_Count
FROM final_LabourForce
WHERE Gender = 'Women' GROUP BY Industry, YEAR ORDER BY Industry, YEAR;""",engine)
earliest_year = femaleCount['YEAR'].min()
latest_year = femaleCount['YEAR'].max()
start = femaleCount[femaleCount['YEAR'] == earliest_year].set_index('Industry')['Female_Count']
end = femaleCount[femaleCount['YEAR'] == latest_year].set_index('Industry')['Female_Count']
percentage_growth =((end - start)/start) * 100
growth_value = percentage_growth.sort_values(ascending=False).to_frame(name='Percentage Growth (%)')
display(growth_value)

#visual
plt.figure(figsize=(14, 6))
plt.barh(growth_value.index, growth_value['Percentage Growth (%)'], color='steelblue')
plt.title('Growth of Female Participation', fontsize=14)
plt.xlabel('Growth Percentage (%)', fontsize=12)
plt.ylabel('Industry Classification', fontsize=12)
plt.show()

"""-----------------------------------------------------------------------------------
The highest growth in female employment (2001-2024) was in *Construction* (147.15%), *Health care* (116.55%), and *Public administration* (101.63%).

-----------------------------------------------------------------------------------

<font size="4">2.1. Why is female participation in agriculture far lower than in other female-led industries?</font>
"""

agricultureFemale = femaleCount[femaleCount['Industry'] == 'Agriculture'].copy()

#how much female participation increased/decreased each year compared to the previous year.
agricultureFemale['Growth_Percentage'] = agricultureFemale.groupby('Industry')['Female_Count'].pct_change() * 100
display(agricultureFemale[['YEAR', 'Growth_Percentage']])

plt.figure(figsize=(14, 6))
plt.plot(agricultureFemale['YEAR'], agricultureFemale['Growth_Percentage'],
         marker='o', color='darkgreen')
plt.xticks(ticks=agricultureFemale['YEAR'], rotation=45, ha='right', fontsize=10)
plt.title('Agriculture Industry: Female Participation Growth (2001-2024)', fontsize=14)
plt.xlabel('Year', fontsize=12)
plt.ylabel('Annual Growth (%)', fontsize=12)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

"""-----------------------------------------------------------------------------------
A few years report sharp declines (2005, 2016, 2021), while others report sharp increases (2013, 2017, 2023), indicating irregular female labor force participation. These fluctuations suggest that external factors such as economic conditions, technological advancements, and policy changes significantly impact women's employment in agriculture.

-----------------------------------------------------------------------------------

<font size="4">3. Are certain industries dominated by specific age groups?</font>
"""

age=pd.read_sql("""SELECT Industry,Age_Group,SUM(Value)
AS Total_Value_in_thousands FROM final_LabourForce
GROUP BY Industry, Age_Group
ORDER BY Total_Value_in_thousands DESC;""",engine)
#display(age)

group1=age.loc[age['Age_Group'] == '15 to 24 years', ['Industry','Total_Value_in_thousands']].sort_values('Industry')
group2=age.loc[age['Age_Group'] == '25 to 54 years', ['Industry','Total_Value_in_thousands']].sort_values('Industry')
group3=age.loc[age['Age_Group']=='55 years and over',['Industry','Total_Value_in_thousands']].sort_values('Industry')

classification=group1['Industry'].values
group_1 = group1['Total_Value_in_thousands'].values
group_2 = group2['Total_Value_in_thousands'].values
group_3= group3['Total_Value_in_thousands'].values

x= np.arange(len(classification))
bar_width=0.2

fig, ax = plt.subplots(figsize=(14, 6))
bar1 = ax.bar(x - bar_width, group_1, width=bar_width, label='15 to 24 years', color='yellowgreen')
bar2 = ax.bar(x, group_2, width=bar_width, label='25 to 54 years', color='steelblue')
bar3 = ax.bar(x + bar_width, group_3, width=bar_width, label='55 years and over', color='orange')
for bars in [bar1, bar2, bar3]:
    for bar in bars:
        height = bar.get_height()
        if height > 0:
            ax.text(bar.get_x() + bar.get_width()/2, height, f'{height:,.0f}',
                    ha='center', va='bottom', fontsize=9, color='black')



plt.xticks(x,classification,rotation=90)
plt.xlabel('Industry Classification')
plt.ylabel('Total Value (thousands)')
plt.legend(loc='upper left')
plt.title('Age Group Distribution Across Industries')
plt.show()

highestIndustry = age.groupby('Age_Group').head(1)
display(highestIndustry)
lowestIndustry = age.groupby('Age_Group').tail(1)
display(lowestIndustry)

"""-----------------------------------------------------------------------------------
- Most of the workers are in the age group of 25 to 54 years. Followed by 15 to 24 years and 55+
- Highest number of workers in each age groups works in the industry *Wholesale and retail trade*
- Lower number of workers in the industry *Forestry and logging and support activities for forestry*


-----------------------------------------------------------------------------------

<font size="4">4. What is the distribution of full-time vs. part-time employment across industries?</font>
"""

characteristics=pd.read_sql("""SELECT Industry,Characteristics,SUM(Value)
AS Total_Value_in_thousands FROM final_LabourForce
WHERE Characteristics IN('Full-time employment','Part-time employment')
GROUP BY Industry,Characteristics ORDER BY Total_Value_in_thousands DESC ;""",engine)
display(characteristics.head())
display(characteristics.tail())
plt.figure(figsize=(12, 6))
full_emply=characteristics.loc[characteristics['Characteristics'] == 'Full-time employment', ['Industry','Total_Value_in_thousands']].sort_values('Industry')
part_emply=characteristics.loc[characteristics['Characteristics'] == 'Part-time employment', ['Industry','Total_Value_in_thousands']].sort_values('Industry')

classification=full_emply['Industry'].values
full_values = full_emply['Total_Value_in_thousands'].values
part_values = part_emply['Total_Value_in_thousands'].values

x= np.arange(len(classification))
bar_width=0.30


fig, ax = plt.subplots(figsize=(14, 6))
bar1 = ax.bar(x - bar_width/2, full_values, width=bar_width, label='Full-time')
bar2 = ax.bar(x + bar_width/2, part_values, width=bar_width, label='Part-time')
for bars in [bar1, bar2]:
    for bar in bars:
        height = bar.get_height()
        if height > 0:
            ax.text(bar.get_x() + bar.get_width()/2, height, f'{height:,.0f}',
                    ha='center', va='bottom', fontsize=9, color='black')


plt.xticks(x,classification,rotation=90, ha='right')
plt.xlabel('Industry Classification')
plt.ylabel('Total Value (thousands)')
plt.legend()
plt.title('Distribution of Full-Time vs Part-Time Employment Across Industries')
plt.show()

"""-----------------------------------------------------------------------------------
- *Wholesale and retail trade* (5,636.5k), *Construction* (4,710.2k), *Health care and social assistance* (4,219.5k) have highest **Full-time employment**
- *Wholesale and retail trade* (1,890.8k) *Health care and social assistance* (1,352.6k), *Accommodation and food services* (1,129.6k) lead in **Part-time employment**
- Notably, *Utilities* and *Forestry and logging and support activities for forestry* have **no Part-time employment**

-----------------------------------------------------------------------------------

<font size="4">5. How has the proportion of male and female employment changed over time?</font>
"""

genderTrend=pd.read_sql("""SELECT Year,Gender,SUM(Value) AS Workforce_Count_in_thousands
FROM final_LabourForce WHERE Gender IN ('Men', 'Women')
GROUP BY Year, Gender ORDER BY Year, Workforce_Count_in_thousands DESC;""",engine)
display(genderTrend)



plt.figure(figsize=(10, 6))
male = genderTrend.loc[genderTrend['Gender'] == 'Men', ['Year', 'Workforce_Count_in_thousands']]
female = genderTrend.loc[genderTrend['Gender'] == 'Women', ['Year', 'Workforce_Count_in_thousands']]
plt.plot(male['Year'], male['Workforce_Count_in_thousands'],
         marker='o', label='Male', color='cornflowerblue', linestyle='-')
plt.plot(female['Year'], female['Workforce_Count_in_thousands'],
         marker='o', label='Female', color='crimson', linestyle='-')

plt.xticks(ticks=male['Year'],rotation=45,ha='right',fontsize=10)
plt.legend(fontsize=12)
plt.xlabel('Year', fontsize=12)
plt.ylabel('Workforce (thousands)', fontsize=12)
plt.title('Trends in Male and Female Workforce Numbers Over Time', fontsize=14)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

"""------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
It is observed that there is no consistent decrease or increase in the gender gap.

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

<font size="4">5.1. How has the employment gender gap varied across the analysis period for industries with the highest male and female employment?</font>
"""

genderDiff="""SELECT YEAR,Industry, SUM(CASE WHEN Gender = 'Men' THEN Value ELSE 0 END) AS MenCount,
SUM(CASE WHEN Gender = 'Women' THEN Value ELSE 0 END) AS WomenCount,
(SUM(CASE WHEN Gender = 'Men' THEN Value ELSE 0 END) - SUM(CASE WHEN Gender = 'Women' THEN Value ELSE 0 END)) AS Difference
FROM final_LabourForce WHERE Characteristics IN ('Full-time employment','Part-time employment')
GROUP BY YEAR, Industry ORDER BY YEAR, Industry;"""
genderDiff=pd.read_sql(genderDiff, engine)
display(genderDiff)

health_female_diff="""SELECT YEAR,Industry, SUM(CASE WHEN Gender = 'Men' THEN Value ELSE 0 END) AS MenCount,
SUM(CASE WHEN Gender = 'Women' THEN Value ELSE 0 END) AS WomenCount,
(SUM(CASE WHEN Gender = 'Men' THEN Value ELSE 0 END) - SUM(CASE WHEN Gender = 'Women' THEN Value ELSE 0 END)) AS Difference
FROM final_LabourForce WHERE Industry = 'Health care and social assistance'
GROUP BY YEAR, Industry ORDER BY YEAR, Industry;"""
health_female_diff=pd.read_sql(health_female_diff, engine)
display(health_female_diff)

health_female_diff_visual = health_female_diff[(health_female_diff["Industry"] == "Health care and social assistance") &
                                (health_female_diff["YEAR"].between(2001, 2024))]

plt.figure(figsize=(12, 6))
sns.lineplot(data=health_female_diff_visual, x="YEAR", y="Difference", marker="o", linestyle="-")
plt.title("Gender Employment Difference in Health care and social assistance (2001-2024)")
plt.xlabel("Year")
plt.ylabel("Employment Difference (Men - Women)")
plt.grid(True)
plt.show()

"""------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Health care and social assistance is the industry in which women outnumber men by the widest margin. Although the number of both genders is increasing, the gender gap continues to widen.

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
"""

construction_male_diff="""SELECT YEAR,Industry, SUM(CASE WHEN Gender = 'Men' THEN Value ELSE 0 END) AS MenCount,
SUM(CASE WHEN Gender = 'Women' THEN Value ELSE 0 END) AS WomenCount,
(SUM(CASE WHEN Gender = 'Men' THEN Value ELSE 0 END) - SUM(CASE WHEN Gender = 'Women' THEN Value ELSE 0 END)) AS Difference
FROM final_LabourForce WHERE Industry = 'Construction'
GROUP BY YEAR, Industry ORDER BY YEAR, Industry;"""
construction_male_diff=pd.read_sql(construction_male_diff, engine)
display(construction_male_diff)


construction_male_diff_visual = construction_male_diff[(construction_male_diff["Industry"] == "Construction") & (construction_male_diff["YEAR"].between(2001, 2024))]
plt.figure(figsize=(12, 6))
sns.lineplot(data=construction_male_diff_visual, x="YEAR", y="Difference", marker="o", linestyle="-")
plt.title("Gender Employment Difference in Construction (2001-2024)")
plt.xlabel("Year")
plt.ylabel("Employment Difference (Men - Women)")
plt.grid(True)
plt.show()

"""------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Construction is the industry in which men outnumber women by the widest margin This gap widened until 2016, then saw a slight reduction until 2021, after which it has been increasing again.

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

## Data Exploration - Part 2
**Employment: Cleaning**
"""

employmentData_sql=employmentData.to_sql(name ='employment_data', if_exists='replace', con = engine, index = False)
print("DataFrame successfully converted to SQL table!")

renaming_query= [
    # Renaming columns
    'ALTER TABLE employment_data RENAME COLUMN `GEO` TO `Province`;',
    'ALTER TABLE employment_data RENAME COLUMN `Type of employee` TO `Employee_Type`;',
    'ALTER TABLE employment_data RENAME COLUMN `North American Industry Classification System (NAICS)` TO `Industry`;'
]
for query in renaming_query:
        conn.execute(text(query))

regex_query=[
        # Cleaning Industry column by replacing "[" to "]" with "" using REGEXP_REPLACE
    """UPDATE employment_data
    SET Industry = REGEXP_REPLACE(Industry, '\\\\[.*?\\\\]', '')
    WHERE Industry REGEXP '\\\\[.*?\\\\]';""",
]

for query in regex_query:
        conn.execute(text(query))

# Removing Goods producing industries,Service producing industries,Industrial aggregate excluding unclassified businesses
classification_filterData=[

    "DROP TABLE IF EXISTS employment_data_filtered;",
    """CREATE TABLE employment_data_filtered AS
    SELECT REF_DATE,Province,CASE
    WHEN `Industry` LIKE 'Forestry, logging and support%'
    THEN 'Forestry and logging and support activities for forestry'
    WHEN `Industry` LIKE 'Trade%'
    THEN 'Wholesale and retail trade' ELSE `Industry` END AS `Industry`,VALUE
    FROM employment_data
    WHERE `Industry` NOT IN (
            "Goods producing industries",
            "Service producing industries",
            "Industrial aggregate excluding unclassified businesses");"""]
for query in classification_filterData:
        conn.execute(text(query))

new_industries_data = pd.read_sql("SELECT DISTINCT Industry FROM employment_data_filtered;",engine)
display(new_industries_data)

# Splitting year and month in table
date_formatted_query = """SELECT
                       REF_DATE,
                       YEAR(STR_TO_DATE(REF_DATE, '%Y-%m')) AS "YEAR",
                       MONTH(STR_TO_DATE(REF_DATE, '%Y-%m')) AS "MONTH",
                       Province,
                       Industry,
                       VALUE
                       FROM
                       employment_data_filtered;"""
date_formatted_data = pd.read_sql(date_formatted_query, engine)
display(date_formatted_data)

date_formatted_data.to_sql('employment_data',engine,if_exists='replace', index=False)

#Aggregation of

# 1. "Information and cultural industries" and "Arts, entertainment and recreation" to "Information, culture and recreation"
# 2.  "Management of companies and enterprises" and "Administrative and support, waste management and remediation services" to "Business, building and other support services"

#Change names of Information and cultural industries and Arts, entertainment and recreation to Information, culture and recreation
# Management of companies and enterprises and Administrative and support, waste management and remediation services to Business, building and other support services

renaming_industry_categories_query = """UPDATE employment_data
                                     SET  Industry =
                                     CASE
                                     WHEN Industry = "Information and cultural industries" THEN "Information, culture and recreation"
                                     WHEN Industry = "Arts, entertainment and recreation" THEN "Information, culture and recreation"
                                     WHEN Industry = "Management of companies and enterprises" THEN "Business, building and other support services"
                                     WHEN Industry = "Administrative and support, waste management and remediation services" THEN "Business, building and other support services"
                                     END
                                     WHERE  Industry IN ("Information and cultural industries",
                                     "Arts, entertainment and recreation",
                                     "Management of companies and enterprises",
                                     "Administrative and support, waste management and remediation services");"""

conn.execute(text(renaming_industry_categories_query))
conn.commit()
new_industries_data = pd.read_sql("SELECT DISTINCT Industry FROM employment_data;",engine)
display(new_industries_data)

# Creating Final table
# Consolidated dataframe
emp_count_final_tab_create_query = [
    "DROP TABLE IF EXISTS Employment_Count;",
    """
        CREATE TABLE Employment_Count AS
        SELECT REF_DATE,
        YEAR,
        MONTH,
        Province,
        Industry,
        CASE
          WHEN Industry IN (
            'Business, building and other support services',
            'Information, culture and recreation')
           THEN SUM(COALESCE(CAST(VALUE AS FLOAT), 0))
          ELSE COALESCE(CAST(VALUE AS FLOAT), 0)
        END AS VALUE
        FROM
        employment_data
        GROUP BY
        REF_DATE,
        YEAR,
        MONTH,
        Province,
        Industry;"""]

for query in emp_count_final_tab_create_query:
    conn.execute(text(query))
conn.commit()
# Checking final table
check_table_query = "SELECT * FROM Employment_Count;"
table_data = pd.read_sql(check_table_query,engine)
display(table_data.head())

# Renaming VALUE column
rename_query = "ALTER TABLE Employment_Count RENAME COLUMN `VALUE` TO `Employment`;"
conn.execute(text(rename_query))
conn.commit()

#Converting Employment table to CSV file
check_table_query = "SELECT * FROM Employment_Count;"
table_data = pd.read_sql(check_table_query,engine)
table_data.to_csv("Employment_Count_clean.csv",index=False)

"""-----------------------------------------------------------------------------------

## Data Exploration - Part 3
**Average Weekly Earnings: Cleaning**
"""

# Cleaning industry column
avgEarning['North American Industry Classification System (NAICS)'] = avgEarning['North American Industry Classification System (NAICS)'] .str.replace(r'\s*\[.*?\]\s*', '', regex=True).str.replace('\n', ' ', regex=True).str.strip()
avgEarning.head()

avgEarning_sql=avgEarning.to_sql('AverageWeekly',engine,if_exists='replace', index=False)

# Removing Goods producing industries,Service producing industries,Industrial aggregate excluding unclassified businesses
classification_filterData = [
    "DROP TABLE IF EXISTS AverageWeekly_filter;",
    """CREATE TABLE AverageWeekly_filter AS
    SELECT REF_DATE,GEO,
        CASE
            WHEN `North American Industry Classification System (NAICS)` LIKE 'Forestry, logging and support%'
                THEN 'Forestry and logging and support activities for forestry'
            WHEN `North American Industry Classification System (NAICS)` LIKE 'Trade%'
                THEN 'Wholesale and retail trade'
            ELSE `North American Industry Classification System (NAICS)`
        END AS `North American Industry Classification System (NAICS)`,
        VALUE
    FROM AverageWeekly
    WHERE `North American Industry Classification System (NAICS)` NOT IN (
            "Goods producing industries",
            "Service producing industries",
            "Industrial aggregate excluding unclassified businesses"
        );"""
]

for query in classification_filterData:
    conn.execute(text(query))
classification_filterData = pd.read_sql( 'SELECT DISTINCT `North American Industry Classification System (NAICS)` FROM AverageWeekly_filter;', engine)
classification_filterData

# Renaming columns
rename_queries = [
    'ALTER TABLE AverageWeekly_filter RENAME COLUMN `GEO` TO `Province`;',
    'ALTER TABLE AverageWeekly_filter RENAME COLUMN `North American Industry Classification System (NAICS)` TO `Industry`;'
]

for query in rename_queries:
        conn.execute(text(query))

# Splitting year and month in table
date_formatted_query = """SELECT
                       REF_DATE,
                       YEAR(STR_TO_DATE(REF_DATE, '%Y-%m')) AS "YEAR",
                       MONTH(STR_TO_DATE(REF_DATE, '%Y-%m')) AS "MONTH",
                       Province,
                       Industry,
                       VALUE
                       FROM
                       AverageWeekly_filter;"""
date_formatted_data = pd.read_sql(date_formatted_query, engine)

# Writing new df into the table
date_formatted_data.to_sql('AverageWeekly',engine,if_exists='replace', index=False)

# Display the new table
avg_weekly_data_query = "SELECT * FROM AverageWeekly;"
avg_weekly_data = pd.read_sql_query(avg_weekly_data_query, engine)

display(avg_weekly_data.head())

#Aggregation of

# 1. "Information and cultural industries" and "Arts, entertainment and recreation" to "Information, culture and recreation"
# 2.  "Management of companies and enterprises" and "Administrative and support, waste management and remediation services" to "Business, building and other support services"

#Change names of Information and cultural industries and Arts, entertainment and recreation to Information, culture and recreation
# Management of companies and enterprises and Administrative and support, waste management and remediation services to Business, building and other support services


renaming_industry_categories_query = """UPDATE AverageWeekly
                                     SET  Industry =
                                     CASE
                                     WHEN Industry = "Information and cultural industries" THEN "Information, culture and recreation"
                                     WHEN Industry = "Arts, entertainment and recreation" THEN "Information, culture and recreation"
                                     WHEN Industry = "Management of companies and enterprises" THEN "Business, building and other support services"
                                     WHEN Industry = "Administrative and support, waste management and remediation services" THEN "Business, building and other support services"
                                     END
                                     WHERE  Industry IN ("Information and cultural industries",
                                     "Arts, entertainment and recreation",
                                     "Management of companies and enterprises",
                                     "Administrative and support, waste management and remediation services");"""

conn.execute(text(renaming_industry_categories_query))
conn.commit()

# Display the new table to confirm the names are changed
new_industries_data = pd.read_sql("SELECT DISTINCT Industry FROM AverageWeekly;",engine)
display(new_industries_data)

#Consolidation of subcategories
# Creating final table
avg_weekly_final_table_create_query = [
    "DROP TABLE IF EXISTS Avg_week_earnings;",
        """CREATE TABLE Avg_week_earnings AS
        SELECT
        REF_DATE,
        YEAR,
        MONTH,
        Province,
        Industry,
        CASE
          WHEN Industry IN (
            'Business, building and other support services',
            'Information, culture and recreation')
           THEN AVG(COALESCE(CAST(VALUE AS FLOAT), 0))
          ELSE COALESCE(CAST(VALUE AS FLOAT), 0)
        END AS VALUE
        FROM
        AverageWeekly
        GROUP BY
        REF_DATE,
        YEAR,
        MONTH,
        Province,
        Industry;"""]

for query in avg_weekly_final_table_create_query:
    conn.execute(text(query))
conn.commit()
# Checking final table
check_table_query = "SELECT * FROM Avg_week_earnings;"
table_data = pd.read_sql(check_table_query,engine)

# Renaming VALUE column
rename_query = "ALTER TABLE Avg_week_earnings RENAME COLUMN `VALUE` TO `Avg_Weekly_Earnings`;"
conn.execute(text(rename_query))
conn.commit()
check_table_query = "SELECT * FROM Avg_week_earnings;"
table_data = pd.read_sql(check_table_query,engine)
display(table_data.head())

#Converting Average Weekly Earnings table to CSV file
table_data.to_csv("avgweek_clean.csv",index=False)

"""-----------------------------------------------------------------------------------

## Data Exploration - Part 4
**GDP Data: Cleaning**
"""

gdp.describe()

#Extracting relevant data and renaming columns
gdp = gdp[(gdp["Value"] == "Current dollars")&(gdp["REF_DATE"] >= 2000)]
gdp.loc[:, "North American Industry Classification System (NAICS)"] = gdp["North American Industry Classification System (NAICS)"].astype(str).str.strip().str.capitalize()
gdp.rename(columns = {"North American Industry Classification System (NAICS)": "NAICS", "REF_DATE" : "Year", "GEO" : "Province"}, inplace = True)

gdp_df_cleaned = gdp.copy()

# merge unique cases Agric;fishing and infor
classes_to_merge = [
    ["Forestry and logging and support activities for forestry","113","1153"],
    ["Information, culture and recreation [51,71]","51", "71"],
    ["Agriculture","111-112", "1100", "1151-1152"]
]

def merge_rows_with_codes(codes: list[str], merge_name: str, df):
    # Filter to find rows to merge
    # print(f"check: {df.shape}")
    temp = "|".join(codes)
    r_codes = r"\[("+ temp +")\]"
    df_to_merge = df[df["NAICS"].str.contains(r_codes, regex = True)]

    # Group by year and sum the GDP values
    merged_values = df_to_merge.groupby("Year", as_index=False).agg({"VALUE": "sum"} )

    merged_values['NAICS'] = merge_name
    merged_values["Province"] = "Alberta"
    merged_values["Value"] = "Current dollars"
    # print(merged_values)

    # 3. Remove the individual industry rows
    df = df[~df["NAICS"].str.contains(r_codes, regex = True)]

    # 4. Append the new merged row
    df = pd.concat([df, merged_values], ignore_index=True)

    # print(result[result["NAICS"] == merge_name])

    # Sort the result by year for better readability
    df.sort_values(by=["Year", "NAICS"], inplace=True)

    return df

for item in classes_to_merge:
    gdp_df_cleaned = merge_rows_with_codes(item[1:], item[0], gdp_df_cleaned)

# Drop rows with NAICS values that contain letters
pattern = r"\[(?=.*[a-zA-Z])[a-zA-Z0-9, \-\s]*\]"
# print(f"sub : {gdp_df_cleaned.shape}")
gdp_df_cleaned = gdp_df_cleaned[~gdp_df_cleaned["NAICS"].str.contains(pattern, regex=True)]
# print(gdp_df_cleaned.shape)

# Drop  remaining sub classes
pattern = r"\[(\d{3,}(?:-\d{3,})?(?:,\d{3,}(?:-\d{3,})?)*)\]$"
# print(f"remaining: {gdp_df_cleaned.shape}")
gdp_df_cleaned = gdp_df_cleaned[~gdp_df_cleaned['NAICS'].str.contains(pattern, regex=True)]
# print(gdp_df_cleaned.shape)

# check if gdp values exist for each year by class
gdp_df_cleaned = gdp_df_cleaned[["NAICS", "VALUE", "Year"]].pivot(index="NAICS", columns="Year", values="VALUE").reset_index()
#gdp_df_cleaned.head()

# fill in missing values with median
gdp_df_cleaned.iloc[:, 1:] = gdp_df_cleaned.iloc[:, 1:].apply(lambda row: row.fillna(row.median()), axis=1)

gdp_df_cleaned = gdp_df_cleaned.melt(id_vars="NAICS", var_name="Year", value_name="VALUE")

gdp_df_cleaned.sort_values(by=["NAICS", "Year"], inplace=True)
gdp_df_cleaned["Province"] = "Alberta"
gdp_df_cleaned["Value"] = "Current dollars"

display(gdp_df_cleaned.isna().sum())
display(gdp_df_cleaned["NAICS"].unique())
#dropping Value column
gdp_df_cleaned = gdp_df_cleaned.drop('Value', axis=1)

"""**Dataframe to SQL - GDP**"""

gdp_df_cleaned.to_sql(name ='GDP_Data', if_exists='replace', con = engine, index = False)

#Cleaning Industry column by replacing "[" to "]" with "" using REGEXP_REPLACE
industry_cleaning_query = """UPDATE GDP_Data
SET NAICS = REGEXP_REPLACE(NAICS, '\\\\[.*?\\\\]', '')
WHERE NAICS REGEXP '\\\\[.*?\\\\]';"""
conn.execute(text(industry_cleaning_query))
conn.commit()

#Renaming column names
rename_queries = ["ALTER TABLE GDP_Data RENAME COLUMN `NAICS` TO `Industry`;",
                  "ALTER TABLE GDP_Data RENAME COLUMN `VALUE` TO `GDP_Value_million`;"]

for query in rename_queries:
    conn.execute(text(query))
conn.commit()

#Aggregation of

# 1. "Information and cultural industries" and "Arts, entertainment and recreation" to "Information, culture and recreation"
# 2.  "Management of companies and enterprises" and "Administrative and support, waste management and remediation services" to "Business, building and other support services"

#Change names of Information and cultural industries and Arts, entertainment and recreation to Information, culture and recreation
# Management of companies and enterprises and Administrative and support, waste management and remediation services to Business, building and other support services

renaming_industry_categories_query = """UPDATE GDP_Data
                                     SET  Industry =
                                     CASE
                                     WHEN Industry = "Retail trade" THEN "Wholesale and retail trade"
                                     WHEN Industry = "Wholesale trade" THEN "Wholesale and retail trade"
                                     WHEN Industry = "Management of companies and enterprises" THEN "Business, building and other support services"
                                     WHEN Industry = "Administrative and support, waste management and remediation services" THEN "Business, building and other support services"
                                     END
                                     WHERE  Industry IN ("Retail trade",
                                     "Wholesale trade",
                                     "Management of companies and enterprises",
                                     "Administrative and support, waste management and remediation services");"""

conn.execute(text(renaming_industry_categories_query))
conn.commit()

# Display the new table to confirm the names are changed
new_industries_data = pd.read_sql("SELECT DISTINCT Industry FROM GDP_Data;",engine)
display(new_industries_data)

# Creating final table
gdp_final_table_create_query =[
    "DROP TABLE IF EXISTS Final_GDP_Data;",

    """CREATE TABLE Final_GDP_Data AS
        SELECT
        YEAR,
        Province,
        Industry,
        CASE
        WHEN Industry IN (
        'Business, building and other support services',
        'Wholesale and retail trade')
         THEN SUM(COALESCE(CAST(GDP_Value_million AS FLOAT), 0))
         ELSE COALESCE(CAST(GDP_Value_million AS FLOAT), 0)
         END AS GDP_Value_million
        FROM
        GDP_Data
        GROUP BY
        YEAR,
        Province,
        Industry;"""]

for query in gdp_final_table_create_query:
    conn.execute(text(query))
conn.commit()
check_table_query = "SELECT * FROM Final_GDP_Data;"
table_data = pd.read_sql(check_table_query,engine)
display(table_data.head())

table_data.shape

#Converting gdp table to CSV
table_data.to_csv("gdpfinal.csv",index=False)

"""-----------------------------------------------------------------------------------

## Joining Tables
"""

# Combining employment and avg weekly earnings
check_table_query1 = "SELECT * FROM Avg_week_earnings;"
table_data1 = pd.read_sql(check_table_query1,engine)
display(table_data1.shape)
# Checking final table
check_table_query2 = "SELECT * FROM Employment_Count;"
table_data2 = pd.read_sql(check_table_query2,engine)
display(table_data2.shape)

# Checking final table GDP
check_table_query3 = "SELECT * FROM Final_GDP_Data;"
table_data3 = pd.read_sql(check_table_query3,engine)
display(table_data3.shape)

# Joining Avg_week_earnings and Employment_Count - Left Join
join_query1 =[ "DROP TABLE IF EXISTS Earning_Employment;",
              """CREATE TABLE Earning_Employment
                AS SELECT a.YEAR,a.MONTH,a.Industry,a.Avg_Weekly_Earnings,e.Employment
                FROM Employment_Count e
                INNER JOIN
                Avg_week_earnings a
                ON a.Industry = e.Industry
                AND a.YEAR=e.YEAR AND a.MONTH=e.MONTH;"""]
for query in join_query1:
    conn.execute(text(query))
check_table_query4 = "SELECT * FROM Earning_Employment;"
table_data4 = pd.read_sql(check_table_query4,engine)
table_data4.shape

# Joining Earning_Employment and Final_GDP_Data - Inner Join
join_query2 = """SELECT t.YEAR,t.MONTH,t.Industry,t.Avg_Weekly_Earnings,t.Employment,g.GDP_Value_million
                FROM Earning_Employment t
                INNER JOIN
                Final_GDP_Data g
                ON t.Industry = g.Industry
                AND t.YEAR=g.YEAR;"""

join_query2_data = pd.read_sql(join_query2, engine)
display(join_query2_data.head())
display(join_query2_data.shape)

#Converting final table to CSV file
join_query2_data.to_csv("finalDataset.csv",index=False)

"""

-----------------------------------------------------------------------------------"""

#Final joined table creation
joined_dataset=pd.read_csv("finalDataset.csv")
final_df = joined_dataset.to_sql('main_table', engine,if_exists='replace', index=False)

# Create a temporary table with industry averages
createmptable = """CREATE TEMPORARY TABLE temp_industry_avgs AS
SELECT Industry,AVG(Avg_Weekly_Earnings) AS industry_avg
FROM main_table WHERE Avg_Weekly_Earnings > 0 GROUP BY Industry;"""
conn.execute(text(createmptable))

#Missing Avg_Weekly_Earnings filled with industry averages in a new table.
createfinal = [
 "DROP TABLE IF EXISTS finalnewDataset_filled;",
 """CREATE TABLE finalnewDataset_filled AS
SELECT
    f.YEAR,
    f.MONTH,
    f.Industry,
    f.Employment,
    f.GDP_Value_million,
    COALESCE(NULLIF(f.Avg_Weekly_Earnings, 0), t.industry_avg) AS Avg_Weekly_Earnings_filled
FROM main_table f
LEFT JOIN temp_industry_avgs t ON f.Industry = t.Industry;"""]
for query in createfinal:
    conn.execute(text(query))

avg_filed_data = pd.read_sql_query("SELECT * FROM finalnewDataset_filled ;",engine)
display(avg_filed_data.head())

"""### Guiding Questions - Part 2

<font size="4">6. Which are the top 5 industries with the highest and lowest average weekly earnings?</font>
"""

# Highest and Lowest Paying Industries :
top5_avg_pay = """
(SELECT
    'Highest Paying' AS Category,
    Industry,
    ROUND(AVG(Avg_Weekly_Earnings_filled), 2) AS Avg_Weekly_Pay
FROM finalnewDataset_filled
WHERE Avg_Weekly_Earnings_filled > 0
GROUP BY Industry
ORDER BY Avg_Weekly_Pay DESC
LIMIT 5)

UNION ALL

(SELECT
    'Lowest Paying' AS Category,
    Industry,
    ROUND(AVG(Avg_Weekly_Earnings_filled), 2) AS Avg_Weekly_Pay
FROM finalnewDataset_filled
WHERE Avg_Weekly_Earnings_filled > 0
GROUP BY Industry
ORDER BY Avg_Weekly_Pay ASC
LIMIT 5)

ORDER BY Category DESC, Avg_Weekly_Pay DESC;
"""
top5_avg_pay = pd.read_sql_query(top5_avg_pay, engine)
display(top5_avg_pay)

industry_avg = joined_dataset.groupby('Industry')['Avg_Weekly_Earnings'].mean().sort_values(ascending=False)
top_5_highest = industry_avg.head(5)
top_5_lowest = industry_avg.tail(5)
plt.figure(figsize=(12, 6))

# Graph for Top 5 highest industries
plt.subplot(1, 2, 1)
top_5_highest.plot(kind='bar')
plt.title('Top 5 Highest paying Industries by Average Weekly Earnings')
plt.xticks()
plt.ylabel('Avg Weekly Earnings')

# Graph for Top 5 lowest industries
plt.subplot(1, 2, 2)
top_5_lowest.plot(kind='bar',color='teal')
plt.title('Top 5 lowest paying Industries by Average Weekly Earnings')
plt.xticks()
plt.ylabel('Avg Weekly Earnings')

plt.tight_layout()
plt.show()

"""-----------------------------------------------------------------------------------

The graph compares the top 5 highest-paying and top 5 lowest-paying industries based on average weekly earnings. It highlights that industries like Mining, Utilities, and Professional Services offer the highest wages, whereas Accommodation, Retail, and Social Assistance sectors have the lowest earnings.

-----------------------------------------------------------------------------------

<font size="4">7. What is the overall distribution of average weekly earnings across different industries?</font>
"""

#Overall Earnings Distribution by Industry
overall_earning = """SELECT
    Industry,
    MIN(Avg_Weekly_Earnings_filled) AS Min_Earnings,
    MAX(Avg_Weekly_Earnings_filled) AS Max_Earnings,
    AVG(Avg_Weekly_Earnings_filled) AS Avg_Earnings,
    COUNT(*) AS total_number
FROM (
    SELECT DISTINCT Industry, Avg_Weekly_Earnings_filled
    FROM finalnewDataset_filled
    WHERE Avg_Weekly_Earnings_filled IS NOT NULL
) AS distinct_data
GROUP BY Industry
ORDER BY Avg_Earnings DESC;"""
overall_earning_data = pd.read_sql_query(overall_earning, engine)
display(overall_earning_data)

overall_earning_data_visual= overall_earning_data.sort_values('Avg_Earnings')
plt.figure(figsize=(10, 6))
plt.barh(overall_earning_data_visual['Industry'], overall_earning_data_visual['Avg_Earnings'], color='steelblue', height=0.6)
for i, industry in enumerate(overall_earning_data_visual['Industry']):
    min_val = overall_earning_data_visual['Min_Earnings'].iloc[i]
    max_val = overall_earning_data_visual['Max_Earnings'].iloc[i]
    plt.hlines(y=i, xmin=min_val, xmax=max_val, color='black', linewidth=1)
    plt.plot(min_val, i, 'ro', markersize=5)
    plt.plot(max_val, i, 'go', markersize=5)
plt.title('Weekly Earnings by Industry')
plt.xlabel('Earnings ($)')
plt.ylabel('Industry')
plt.legend(['Min Earnings', 'Max Earnings', 'Average Earnings'])
plt.tight_layout()
plt.show()

"""-----------------------------------------------------------------------------------
This graph shows the range of weekly earnings across different industries. The blue bars represent the average earnings, the red dots show the highest earnings, and the green dots show the average earnings. Industries like mining and utilities have higher average and maximum earnings, while industries like accommodation and food services have the lowest. This helps us understand how pay varies across industries and which sectors offer better income opportunities.

-----------------------------------------------------------------------------------
"""

# Monthly Earnings Trends by Industry
trends="""SELECT
    Industry,
    MONTH,
    AVG(Avg_Weekly_Earnings_filled) AS Avg_Weekly_Earnings
FROM finalnewDataset_filled
WHERE Avg_Weekly_Earnings_filled > 0
GROUP BY Industry, MONTH
ORDER BY Industry, MONTH;"""
trends_data = pd.read_sql_query(trends, engine)
display(trends_data.head())

plt.figure(figsize=(12, 6))

for industry in trends_data['Industry'].unique():
    industry_data = trends_data[trends_data['Industry'] == industry]
    plt.plot(industry_data['MONTH'], industry_data['Avg_Weekly_Earnings'],
             label=industry, marker='o')


plt.xlabel('Month')
plt.ylabel('Average Weekly Earnings ($)')
plt.title('Average Weekly Earnings by Industry Over Months')
plt.legend(title='Industry', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid()
plt.tight_layout()
plt.show()

"""-----------------------------------------------------------------------------------
The line chart shows that high-paying industries like "Mining, quarrying, and oil and gas extraction" and "Utilities" maintain consistently higher average weekly earnings across the months, while industries such as "Accommodation and food services" and "Wholesale and retail trade" remain at the lower end.


-----------------------------------------------------------------------------------

<font size="4">8. What are the average weekly earnings and average employment for each industry?</font>
"""

avgEarning_avgEmploy="""SELECT
    Industry,
    AVG(Avg_Weekly_Earnings) AS Avg_Wage,
    AVG(Employment) AS Avg_Employment,
    COUNT(*) AS Data_Points
FROM main_table
WHERE Avg_Weekly_Earnings > 0 AND Employment > 0
GROUP BY Industry
ORDER BY Avg_Wage DESC;"""

avgEarning_avgEmploy_data = pd.read_sql_query(avgEarning_avgEmploy, engine)
display(avgEarning_avgEmploy_data)

#Plotting Average weekly earning vs Average Employment by industry.
sns.set(style="white")
avgEarning_avgEmploy_data = avgEarning_avgEmploy_data.sort_values(by='Avg_Wage', ascending=False)
fig, ax1 = plt.subplots(figsize=(14, 12))
sns.barplot(data=avgEarning_avgEmploy_data, x='Industry', y='Avg_Wage', color='steelblue')
plt.xticks(rotation=90, ha='right')
ax2 = ax1.twinx()
sns.lineplot(data=avgEarning_avgEmploy_data, x='Industry', y='Avg_Employment', marker='o', color='crimson')
for i, row in avgEarning_avgEmploy_data.iterrows():
    ax1.text(i, row['Avg_Wage'] + 20, f"{row['Avg_Wage']:.2f}", ha='center', fontsize=9)
ax1.set_ylabel('Average Weekly Earnings ($)', fontsize=12)
ax2.set_ylabel('Average Employment', fontsize=12)
ax1.set_xlabel('Industry', fontsize=12)
plt.title('Average Weekly Earnings and Employment by Industry', fontsize=16)
plt.tight_layout()
plt.show()

"""-----------------------------------------------------------------------------------
This graph shows the relationship between average weekly wages and average employment across different industries. The blue bars represent the average weekly wages for each industry, while the red line shows the average number of employees in those industries. Industries like mining and utilities have the highest average wages, but the number of employees is less. On the other hand, industries like wholesale and retail trade have more employees but lower average wages.

-----------------------------------------------------------------------------------

<font size="4">8.1. Do higher employment opportunities indicate lower wages? (Hypothesis testing)</font>
"""

from scipy import stats

df = pd.read_sql_query("SELECT * FROM finalnewDataset_filled", engine)
df = df[(df['Avg_Weekly_Earnings_filled'] > 0) & (df['Employment'] > 0)]
# Calculate the 33rd and 66th percentiles for Employment
p33 = df['Employment'].quantile(0.33)
p66 = df['Employment'].quantile(0.66)
# Employment Level categories using the percentiles
def categorize_employment(emp):
    """Assigns 'Low', 'Medium', or 'High' based on employment percentiles."""
    if emp <= p33:
        return 'Low'
    elif emp <= p66:
        return 'Medium'
    else:
        return 'High'

df['Employment_Level'] = df['Employment'].apply(categorize_employment)

low = df[df['Employment_Level'] == 'Low']['Avg_Weekly_Earnings_filled']
medium = df[df['Employment_Level'] == 'Medium']['Avg_Weekly_Earnings_filled']
high = df[df['Employment_Level'] == 'High']['Avg_Weekly_Earnings_filled']
f_stat, p_value = stats.f_oneway(low, medium, high)
print(f"ANOVA Results: F-statistic = {f_stat:.2f}, p-value = {p_value:.4f}")
if p_value < 0.05:
    print("There is a significant difference between employment groups.")
else:
    print("No significant difference between employment groups.")

plt.figure(figsize=(8, 5))
sns.boxplot(x='Employment_Level', y='Avg_Weekly_Earnings_filled', hue='Employment_Level',data=df, palette="viridis")
plt.title("Average Weekly Earnings by Employment Level")
plt.xlabel("Employment Level")
plt.ylabel("Avg Weekly Earnings")
plt.grid(True)
plt.show()

"""-----------------------------------------------------------------------------------
- The ANOVA results show a high F-statistic of 191.48 and a p-value of 0.0000, indicating that there is a statistically significant difference in average weekly earnings between the different employment groups (Low, Medium, High). This suggests that employment levels have a clear impact on earnings.
  
- The chart illustrates that average weekly earnings are highest for the "Medium" employment level, ranging around 2,500 dollars, while the "High" and "Low" employment levels show lower and more similar earnings, around 2,000 to 2,200 dollars, suggesting that moderate employment levels correlate with higher wages compared to extremes.
-----------------------------------------------------------------------------------

<font size="4">9. Which industries are biggest and least in terms of providing employment opportunities?</font>
"""

employment_providers= """(SELECT 'Top Employer' AS category,
        Industry,Employment
    FROM main_table
    GROUP BY Industry
    ORDER BY Employment DESC LIMIT 5)
UNION ALL
(SELECT 'Bottom Employer' AS category,
    Industry,Employment
    FROM main_table
    GROUP BY Industry
    ORDER BY Employment ASC LIMIT 5)
ORDER BY category DESC,Employment DESC;"""

employment_providers_data = pd.read_sql_query(employment_providers, engine)
display(employment_providers_data)

sns.set(style="white")
plt.figure(figsize=(10, 6))
sns.barplot(x='Employment', y='Industry', hue='category', data=employment_providers_data, palette='viridis')
plt.title('Top and Bottom Employers by Industry', fontsize=14)
plt.xlabel('Employment', fontsize=12)
plt.ylabel('Industry', fontsize=12)

plt.tight_layout()
plt.grid()
plt.show()

"""-----------------------------------------------------------------------------------
This bar chart shows the top and bottom employers by industry based on employment numbers. The Wholesale and Retail Trade industry is the largest employer, followed by Manufacturing and Health Care and Social Assistance. The Top Employer category is shown in dark orange, while the Bottom Employer category is in light orange. Industries such as Utilities and Forestry and Logging have the lowest employment numbers. The chart highlights the disparity in employment across different industries.

-----------------------------------------------------------------------------------

<font size="4">10. Which industries in Alberta lost the most jobs during the COVID period (March 2020 to December 2021)?</font>
"""

covid_joblost="""
SELECT
    Industry,
    SUM(CASE WHEN Year < 2020 THEN Employment ELSE 0 END) AS Jobs_Before_COVID,
    SUM(CASE WHEN Year BETWEEN 2020 AND 2021 AND Month BETWEEN 3 AND 12 THEN Employment ELSE 0 END) AS Jobs_During_COVID,
    SUM(CASE WHEN Year < 2020 THEN Employment ELSE 0 END) -
    SUM(CASE WHEN Year BETWEEN 2020 AND 2021 AND Month BETWEEN 3 AND 12 THEN Employment ELSE 0 END) AS Jobs_Lost
FROM finalnewDataset_filled
GROUP BY Industry
HAVING SUM(CASE WHEN Year < 2020 THEN Employment ELSE 0 END) > 0
ORDER BY Jobs_Lost DESC ;  """
covid_joblost_data = pd.read_sql_query(covid_joblost, engine)
display(covid_joblost_data)

"""-----------------------------------------------------------------------------------

<font size="4">11. Did industries with higher GDP before COVID suffer less during the pandemic?</font>
"""

covid_suffer = """
with yearly_gdp as (
    select
        Industry,
        YEAR,
        sum(distinct GDP_Value_million) / count(distinct MONTH) as annual_gdp
    from main_table
    where year between 2016 and 2022
    group by Industry, YEAR
),
yearly_growth as (
    select
        Industry,
        YEAR,
        annual_gdp,
        lag(annual_gdp) over (partition by Industry order by YEAR) as previous_year_gdp
    from yearly_gdp
)
select
    Industry,
    YEAR,
    ((annual_gdp - previous_year_gdp) / previous_year_gdp) * 100 as growth_rate
from yearly_growth
where previous_year_gdp is not NULL
order by Industry, YEAR;

"""
covid_suffer_data=pd.read_sql(covid_suffer, conn)
display(covid_suffer_data.head(10))

# Pivot the dataframe for heatmap format
pivot = covid_suffer_data.pivot(index = "Industry", columns = "YEAR", values = "growth_rate")
fig, ax = plt.subplots(figsize=(12, 8))
sns.heatmap(pivot, annot=True, fmt=".2f", cmap="RdYlGn", linewidths=0.5, center=0)
plt.title("Yearly GDP Growth Rates by Industry (2017-2022)")
plt.xlabel("Year")
plt.ylabel("Industry")
#plt.savefig('gdp_growth_2015_2020_heat.png', bbox_inches='tight')
plt.show()

# Pre-COVID average GDP data
q1 = """
create or replace temporary table pre_covid_gdp as
select
    Industry,
    avg(distinct GDP_Value_million) as avg_gdp_pre_covid
from main_table
where YEAR between 2015 and 2018
group by Industry;
"""
# calculate GDP change over COVID period
q2 = """
create or replace temporary table covid_gdp as
select
    Industry,
    avg(distinct GDP_Value_million) as avg_gdp_covid
from main_table
where YEAR between 2019 and 2021
group by Industry;
"""
# Table aggregation
query = """
select
    p.Industry,
    p.avg_gdp_pre_covid,
    c.avg_gdp_covid,
    round(((c.avg_gdp_covid - p.avg_gdp_pre_covid) / p.avg_gdp_pre_covid) * 100, 2) as gdp_change_percent
from pre_covid_gdp p
join covid_gdp c on p.Industry = c.Industry
order by gdp_change_percent ASC;
"""

for q in [q1, q2]:
    conn.execute(sq.text(q))
df = pd.read_sql(query, conn)
display(df.head())


# Plot
sns.set_theme(style="whitegrid")
df_sorted = df.sort_values('gdp_change_percent', ascending=True)
fig, ax = plt.subplots(figsize=(12, 6))
sns.barplot(data=df_sorted, x='Industry', y='gdp_change_percent', ax=ax, hue='Industry',palette='viridis')
ax.set_title('% GDP Change  by Industry (2015-2018 vs 2019-2021)')
ax.set_xlabel('Industry Classification')
ax.set_ylabel('GDP Change (%)')
plt.xticks(rotation=90)
plt.show()

"""-----------------------------------------------------------------------------------
- <p>The Mining, Quarrying, and Oil & Gas Extraction industry maintained the #1 rank in GDP across all years except for in 2020**, when it fell to rank 2
The drop in 2020 could have been due to the COVID-19 pandemic or market fluctuations in oil and gas. It recovered in 2021, with its GDP reaching its highest recorded value $88.8 billion, then stabilized in 2022 at $64.5 billion.</p>

- <p>The Real Estate and Rental and Leasing Stability industry consistently remained at rank 2 from 2017 to 2021. However, in 2022, it dropped to rank 3, showing a significant decline in GDP from $40.7 billion dollars in 2021, to $26.2 billion in 2022. The decline suggests either a slowdown in real estate activity or reduced demand in rental and leasing markets.</p>

- <p>Construction showed a sharp drop in 2021 but recovered in 2022. The construction industry maintained rank 3 until 2020 but dropped to rank 5 in 2021. It however rebound in 2022, climbing back to rank 2 with GDP $26.6 billion. The decline in its growth could be explained by restrictions enforced during the pandemic  which is why the trend reverses after economic activities resumed. Out of the 5 highest producing industries pre-covid, Construction seemed to be the most negatively impacted. </p>


- <p>Wholesale and Retail Trade ranked 4th from 2017 to 2019, but moved up to rank 3 in 2020 and 2021. This trend could be driven by pandemic-driven shifts in retail, e-commerce, and supply chain activity. Post-pandemic, it falls back to rank 4 in 2022, suggesting a return to more typical trade patterns. Retail trade and wholesale seemed to benefit from the pandemic, likely due to pandemic-related changes in consumer behavior.</p>

- <p>Manufacturing ranked 5th every year except 2021, when it moves up to rank 4 but only temporarily. More broadly, Manufacturing seems to show a steady decline in GDP declining from $25.2 billion in 2017, to $20.5 billion in 2022. This is likely due to employment disruptions caused by periodic lockdowns during the pandemic or changes in consumer consumption patterns of manufactured foods due to post-pandemic inflation.</p>



-----------------------------------------------------------------------------------

<font size="4">12. Which industries have seen the highest growth in GDP, and how do they compare in employment levels/average earnings?</font>
"""

# Get yearly GDP values
q1 = """
create or replace temporary table yearly_gdp as
select
    Industry,
    YEAR,
    sum(distinct GDP_Value_million) as yearly_gdp
from main_table
group by Industry, YEAR;
"""

# GDP growth
q2 = """

create or replace temporary table gdp_growth as
select
    Industry,
    avg(case when YEAR between 2001 and 2005 then yearly_gdp else NULL end) as gdp_early,
    avg(case when YEAR between 2019 and 2023 then yearly_gdp else NULL end) as gdp_recent
from yearly_gdp
group by Industry;
"""

# Employment and earnings trends
q3 = """
create or replace temporary table employment_earnings as
select
    Industry,
    avg(case when YEAR between 2001 and 2005 then Employment else NULL end) as emp_early,
    avg(case when YEAR between 2019 and 2023 then Employment else NULL end) as emp_recent,
    avg(case when YEAR between 2001 and 2005 then Avg_Weekly_Earnings else NULL end) as earnings_early,
    avg(case when YEAR between 2019 and 2023 then Avg_Weekly_Earnings else NULL end) as earnings_recent
from main_table
group by Industry;
"""

# Join and compare
query ="""
select
    g.Industry,
    round(((g.gdp_recent - g.gdp_early) / g.gdp_early) * 100, 2) as gdp_growth_percent,
    round(((e.emp_recent - e.emp_early) / e.emp_early) * 100, 2) as employment_growth_percent,
    round(((e.earnings_recent - e.earnings_early) / e.earnings_early) * 100, 2) as earnings_growth_percent
from gdp_growth g
join employment_earnings e on g.Industry = e.Industry
order by gdp_growth_percent desc;
"""


for q in [q1, q2, q3]:
    conn.execute(sq.text(q))

df = pd.read_sql(query, conn)
display(df.head())

# Plot heatmap of correlation matrix
corr = df[['gdp_growth_percent', 'employment_growth_percent', 'earnings_growth_percent']].corr()
fig, ax = plt.subplots(figsize=(8, 6))
sns.heatmap(corr, annot=True, cmap='GnBu', center=0, ax=ax)
plt.title('Correlation Matrix: GDP, Employment, and Earnings Growth')
plt.show()

sns.set(style="whitegrid")
df_melted = df.melt(id_vars='Industry',
                        value_vars=['gdp_growth_percent', 'employment_growth_percent', 'earnings_growth_percent'],
                        var_name='Metric', value_name='Growth (%)')
fig, ax = plt.subplots(figsize=(12, 6))
sns.barplot(data=df_melted, x='Industry', y='Growth (%)', hue='Metric', ax=ax)
ax.set_title('GDP, Employment, and Earnings Growth by Industry (2001-2005 vs 2019-2023)')
ax.set_xlabel('Industry Classification')
ax.set_ylabel('Growth (%)')
plt.xticks(rotation=90)
plt.legend(title='Metric')
plt.show()

"""-----------------------------------------------------------------------------------
**1. Volatility in the Finance and Insurance Sector**
- The finance and insurance industry shows high fluctuations, with strong positive growth from 2005 to 2006 but sharply declines in 2021 (-2.54%) and 2023 (0.00%).

- <p> The construction industry exhibits high growth in the mid-2000s, peaking around 2006 to 2007.
However, it experienced major declines in 2009 (-1.66%) and 2016 (-1.55%), potentially due to economic crises like the 2008 market crisis and the 2016 Alberta Oil crisis. A strong rebound in 2021 (1.46%) could indicate a post-pandemic recovery in housing or infrastructure projects.</p>

- <p> Accommodation and Food Services dropped sharply in 2020 (-2.92%), likely due to COVID-19 lockdowns, travel restrictions, and reduced consumer activity.
The industry made a strong recovery in 2021 (1.03%), which suggests that restaurants, hotels, and tourism were able to recover relatively quickly post-pandemic. The decline from 2022 to 2023 might be due to economic instability and inflation which have changed consumer spending habits.</p>


- <p> Educational Services showed strong  early growth from 2001 to 2006 followed by fluctuations.
The industry has shown a consistent decline after 2019, with negative growth in 2021 (-0.86%) and 2022 (-1.95%).
This might reflect reduced public funding, changing education models (remote learning), or demographic shifts.</p>

- <p> Business, Building, and Other Support Services had significant early growth from 2001 to 2006, followed by declines in 2009 (-0.52%), 2017 (-0.68%), and 2022 (-0.72%). Factors that could be at play include increase in business outsourcing, automation, and economic cycles.</p>


-----------------------------------------------------------------------------------
"""

i = inspect(engine)
print("Tables in the database:", i.get_table_names())

"""# Discussion

<p>Through this project, we learned how combining multiple datasets enhances data analysis by providing deeper insights that cannot be obtained from individual datasets alone. We explored techniques for cleaning and storing big data in databases and gained hands-on experience in interacting with a server using SQL.</p>
<p>Key skills acquired include extracting relevant data by removing redundancy and irrelevant information, handling null values, and mapping subcategories into main categories (in our case, industries). We also learned and applied different dataset merging techniques, dealing with varied shapes and join types.</p>
<p>Additionally, we developed a strong understanding of SQL queries for grouping, aggregation, and ranking. We learned how to integrate Pandas with SQL for efficient data manipulation and performed various database operations. Finally, we applied data visualization techniques using Matplotlib, Seaborn, and other tools to present insights effectively.</p>
<p>One of the challenges our project faced was related to data quality and retrieval. Gaps and inconsistencies in our dataset sometimes created roadblocks, as missing values and discrepancies between aggregate categories and subcategories limited the range of research questions we could explore.   
</p>
<p>Data retrieval and table joins were another challenge. Joining our tables and retrieving data from our joins was a challenging aspect of our project which made us consider exploring in further work if graph databases like Neo4j or document stores like MongoDB could simplify our queries and streamline our analysis. We are also considering to include datasets for part-time and full-time wages for further research.
</p>
<p>Additionally, our work featured some repeated code, making our workflow more time-consuming than necessary. We are considering exploring a more modular approach in future work, such as using stored functions, to improve efficiency and maintainability.     
</p>

# Conclusion

<p>Alberta's labor market shows some distinct patterns across industries, influenced by gender, age, employment type, and macroeconomic shifts. Our analysis highlights disparities in workforce composition, employment trends over time, and the relationship between wages, employment levels, and industry performance. </p>

<p>Employment distribution across industries remains highly gendered. Men dominate sectors like Construction (9,822.8K), Wholesale and Retail Trade (8,509.2K), and Mining, Quarrying, and Oil & Gas Extraction (5,396.1K), while women lead in Healthcare and Social Assistance (9,553.8K) and Wholesale and Retail Trade (7,803K). Despite Wholesale and Retail Trade employing both genders in high numbers compared to other industries, the industry maintains a male-biased disparity. </p>

<p>Female employment has grown significantly in several traditionally male-dominated industries. Between 2001 and 2024, Construction (147.15%), Healthcare (116.55%), and Public Administration (101.63%) saw the highest percentage growth in female participation. However, agriculture remains an anomaly. Female employment in the sector.</p>

# Reference

1. Ian. (2021, November 7). 3 Ways to Separate the Year, Month, and Day from a Date in MariaDB. https://database.guide/3-ways-to-separate-the-year-month-and-day-from-a-date-in-mariadb/
2. Open Source Database (RDBMS) for the enterprise | MariaDB. (n.d.). MariaDB. https://mariadb.com/docs/skysql-dbaas/ref/xpand/functions/STR_TO_DATE/
3. MariaDB Tutorial. (2020, April 11). MariaDB Update Statement by practical examples. https://www.mariadbtutorial.com/mariadb-basics/mariadb-update/
4. MySQL updating a column's values with multiple conditions - https://stackoverflow.com/questions/64620440/mysql-updating-a-columns-values-with-multiple-conditions
5. Adding and changing data in MariaDB. (n.d.). MariaDB KnowledgeBase. https://mariadb.com/kb/en/adding-and-changing-data-in-mariadb/
6. CASE Statement - MariaDB Knowledge Base - https://mariadb.com/kb/en/case-statement/
7. Python and SQL Core - using INNER JOIN with Python and SQLite from scratch - https://www.youtube.com/watch?v=X3RM39Sucm4
8. SQL Examples. https://www.w3schools.com/sql/sql_examples.asp
9. SQL Query Examples and Tutorial, DataCamp -  https://www.datacamp.com/tutorial/sql-query-examples-and-tutorial
10. Swain, Abhipsa. “How to Rename Column Name in SQL?” Scaler Topics, 4 Aug. 2022, https://www.scaler.com/topics/rename-column-name-in-sql/
11. SQL Not Equal To - Syntax, Use Cases, and Examples. https://hightouch.com/sql-dictionary/sql-not-equal-to
12. YouTube. https://www.youtube.com/watch?v=d63LPGO_Avs
13. Mercatante, Steven. “How to Remove Square Brackets and Anything between Them with a Regex?” Stack Overflow, 13 May 2019, https://stackoverflow.com/q/2359921
14. Pandas Documentation — Pandas 2.2.3 Documentation. http://pandas.pydata.org/docs/
15. Erkec, Esat. “Working with SQL NULL Values.” SQL Shack - Articles about Database Auditing, Server Performance, Data Recovery, and More, 19 May 2021, https://www.sqlshack.com/working-with-sql-null-values/
16. Working with Engines and Connections — SQLAlchemy 2.0 Documentation. https://docs.sqlalchemy.org/en/20/core/connections.html
17. “MariaDB GROUP BY Clause.” GeeksforGeeks, 25 Dec. 2023, https://www.geeksforgeeks.org/mariadb-group-by-clause/.
18. Forrester, R. (2024, September 26). SQL Conditional Joins: Practical Guide. Five. https://five.co/blog/sql-conditional-joins/
19. Grouped Bar Charts with Labels in Matplotlib. (2019, March 26). https://www.pythoncharts.com/matplotlib/grouped-bar-charts-matplotlib/
20. Payne, R. (2023b, March 9). Working with NULL Values in SQL. Database Journal. https://www.databasejournal.com/features/sql-null-values/#:~:text=The%20SQL%20COALESCE%20and%20IFNULL,it%20returns%20the%20second%20argument.
21. SQLAlchemy - Getting a list of tables. (n.d.). Stack Overflow. https://stackoverflow.com/questions/6473925/sqlalchemy-getting-a-list-of-tables
22. W3Schools.com. (n.d.). https://www.w3schools.com/sql/sql_like.asp
23. Using cast function and coalesce function to generate a fixed width file format. (n.d.). Stack Overflow. https://stackoverflow.com/questions/42426285/using-cast-function-and-coalesce-function-to-generate-a-fixed-width-file-format
24. GeeksforGeeks. (2022, February 28). How to Execute raw SQL in SQLAlchemy. GeeksforGeeks. https://www.geeksforgeeks.org/how-to-execute-raw-sql-in-sqlalchemy/
25. Sqlalchemy. (n.d.). Can `sqlalchemy.inspect(engine).get_columns()` return values already converted to Python types without previous definition of table in `sqlalchemy.Table`? · sqlalchemy/sqlalchemy · Discussion #11689. GitHub. https://github.com/sqlalchemy/sqlalchemy/discussions/11689
"""

